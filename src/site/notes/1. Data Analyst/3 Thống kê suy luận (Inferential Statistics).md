---
{"dg-publish":true,"permalink":"/1-data-analyst/3-thong-ke-suy-luan-inferential-statistics/","updated":"2025-11-24T09:12:38.483+07:00"}
---

# 1. **L·∫•y m·∫´u (Sampling)**
L·∫•y m·∫´u l√† qu√° tr√¨nh ch·ªçn ra m·ªôt t·∫≠p h·ª£p con (m·∫´u) t·ª´ t·ªïng th·ªÉ (population) ƒë·ªÉ ti·∫øn h√†nh ƒëo l∆∞·ªùng, ph√¢n t√≠ch m√† kh√¥ng c·∫ßn thu th·∫≠p d·ªØ li·ªáu t·ª´ to√†n b·ªô t·ªïng th·ªÉ.
## **L·∫•y m·∫´u ng·∫´u nhi√™n ƒë∆°n (Simple Random Sampling ‚Äì SRS):** 
M·ªói ph·∫ßn t·ª≠ trong t·ªïng th·ªÉ c√≥ c√πng x√°c su·∫•t ƒë∆∞·ª£c ch·ªçn v√†o m·∫´u. Vi·ªác ch·ªçn ƒë∆∞·ª£c th·ª±c hi·ªán ng·∫´u nhi√™n, kh√¥ng thi√™n l·ªách.

**V√≠ d·ª•:**
B·∫°n c√≥ 1000 kh√°ch h√†ng, d√πng random function ƒë·ªÉ ch·ªçn ng·∫´u nhi√™n 100 ng∆∞·ªùi.

**∆Øu ƒëi·ªÉm:**
- D·ªÖ hi·ªÉu, d·ªÖ th·ª±c hi·ªán b·∫±ng Excel/Python
- Gi·∫£m sai l·ªách h·ªá th·ªëng (bias)

**Nh∆∞·ª£c ƒëi·ªÉm:**
- C·∫ßn danh s√°ch ƒë·∫ßy ƒë·ªß to√†n b·ªô t·ªïng th·ªÉ
- Kh√¥ng ƒë·∫£m b·∫£o ƒë·∫°i di·ªán cho c√°c nh√≥m nh·ªè (n·∫øu t·ªïng th·ªÉ kh√¥ng ƒë·ªìng nh·∫•t)
## **L·∫•y m·∫´u ph√¢n t·∫ßng (Stratified Sampling)**: 
Chia t·ªïng th·ªÉ th√†nh c√°c t·∫ßng (strata) d·ª±a tr√™n m·ªôt bi·∫øn ph√¢n nh√≥m (gi·ªõi t√≠nh, khu v·ª±c, ƒë·ªô tu·ªïi...), sau ƒë√≥ l·∫•y m·∫´u ng·∫´u nhi√™n trong t·ª´ng t·∫ßng theo t·ª∑ l·ªá.

**V√≠ d·ª•:**
B·∫°n c√≥ 60% kh√°ch h√†ng n·ªØ, 40% nam ‚Üí M·∫´u 100 ng∆∞·ªùi s·∫Ω ch·ªçn 60 n·ªØ + 40 nam.

**∆Øu ƒëi·ªÉm:**
- ƒê·∫£m b·∫£o m·ªói nh√≥m quan tr·ªçng ƒë·ªÅu ƒë∆∞·ª£c ƒë·∫°i di·ªán trong m·∫´u
- TƒÉng ƒë·ªô ch√≠nh x√°c khi c√≥ s·ª± kh√¥ng ƒë·ªìng ƒë·ªÅu gi·ªØa c√°c nh√≥m

**Nh∆∞·ª£c ƒëi·ªÉm:**
- C·∫ßn bi·∫øt th√¥ng tin ph√¢n nh√≥m tr∆∞·ªõc
- Ph·ª©c t·∫°p h∆°n khi s·ªë nh√≥m l·ªõn

## **L·∫•y m·∫´u h·ªá th·ªëng (Systematic Sampling)**: 
Ch·ªçn ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n ng·∫´u nhi√™n, sau ƒë√≥ l·∫•y c√°c ph·∫ßn t·ª≠ ti·∫øp theo c√°ch ƒë·ªÅu nhau theo kho·∫£ng k.
**C√¥ng th·ª©c kho·∫£ng c√°ch l·∫•y m·∫´u:**
$$k=‚åä\frac{n}{N‚Äã}‚åã$$
Trong ƒë√≥:
- N: k√≠ch th∆∞·ªõc t·ªïng th·ªÉ
- n: s·ªë m·∫´u mu·ªën l·∫•y
**V√≠ d·ª•:**
B·∫°n c√≥ 1000 ng∆∞·ªùi, mu·ªën l·∫•y 100 ng∆∞·ªùi ‚Üí k=10k = 10k=10. Ch·ªçn ng∆∞·ªùi th·ª© 7, sau ƒë√≥ ng∆∞·ªùi 17, 27, 37, v.v.

**∆Øu ƒëi·ªÉm:**
- D·ªÖ th·ª±c hi·ªán (kh√¥ng c·∫ßn random to√†n b·ªô)
- Ph√¢n ph·ªëi ƒë·ªÅu

**Nh∆∞·ª£c ƒëi·ªÉm:**
- N·∫øu t·ªïng th·ªÉ c√≥ **chu k·ª≥** tr√πng v·ªõi kho·∫£ng c√°ch m·∫´u ‚Üí t·∫°o thi√™n l·ªách

| Ph∆∞∆°ng ph√°p    | C√°ch ch·ªçn m·∫´u               | ∆Øu ƒëi·ªÉm               | Nh∆∞·ª£c ƒëi·ªÉm                     |
| -------------- | --------------------------- | --------------------- | ------------------------------ |
| Ng·∫´u nhi√™n ƒë∆°n | Ng·∫´u nhi√™n to√†n b·ªô          | D·ªÖ hi·ªÉu, kh√°ch quan   | C√≥ th·ªÉ thi·∫øu ƒë·∫°i di·ªán nh√≥m nh·ªè |
| Ph√¢n t·∫ßng      | Chia nh√≥m ‚Üí ch·ªçn ng·∫´u nhi√™n | ƒê·∫°i di·ªán t·ªët c√°c nh√≥m | C·∫ßn ph√¢n nh√≥m s·∫µn              |
| H·ªá th·ªëng       | Ch·ªçn ng·∫´u nhi√™n + c√°ch ƒë·ªÅu  | Nhanh, ƒë∆°n gi·∫£n       | D·ªÖ l·ªách n·∫øu d·ªØ li·ªáu c√≥ chu k·ª≥  |
- [[1. Data Analyst/3.1 X√°c ƒë·ªãnh c·ª° m·∫´u\|3.1 X√°c ƒë·ªãnh c·ª° m·∫´u]] (Sample size) ‚Äì t√≠nh to√°n v√† ∆∞·ªõc l∆∞·ª£ng
# 2. **∆Ø·ªõc l∆∞·ª£ng tham s·ªë**
- Kho·∫£ng tin c·∫≠y (Confidence Interval):
$$\bar{x}¬±Z_{\alpha/2} \cdot \frac{s}{\sqrt{n}}$$
# 3. **Ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt (Hypothesis Testing)**
| Th√†nh ph·∫ßn                   | Gi·∫£i th√≠ch                                     |
| ---------------------------- | ---------------------------------------------- |
| Gi·∫£ thuy·∫øt g·ªëc $$H_0$$‚Äã      | Kh√¥ng c√≥ s·ª± kh√°c bi·ªát                          |
| Gi·∫£ thuy·∫øt thay th·∫ø $$H_1$$‚Äã | C√≥ s·ª± kh√°c bi·ªát                                |
| p-value                      | X√°c su·∫•t quan s√°t d·ªØ li·ªáu nh∆∞ v·∫≠y n·∫øu H0‚Äã ƒë√∫ng |
| Alpha Œ±                      | M·ª©c √Ω nghƒ©a (th∆∞·ªùng l√† 0.05)                   |
## ‚úÖKi·ªÉm ƒë·ªãnh t (t-tests)
D√πng ƒë·ªÉ **so s√°nh trung b√¨nh** gi·ªØa c√°c nh√≥m khi d·ªØ li·ªáu li√™n t·ª•c v√† ph√¢n ph·ªëi g·∫ßn chu·∫©n.
### a. **One-sample t-test (ki·ªÉm ƒë·ªãnh 1 m·∫´u)**
**M·ª•c ti√™u:** So s√°nh trung b√¨nh c·ªßa m·ªôt m·∫´u v·ªõi m·ªôt gi√° tr·ªã c·ª• th·ªÉ $$Œº_0$$
#### üîç C√¥ng th·ª©c:
$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$‚Äã‚Äã

**V√≠ d·ª•:** So s√°nh th·ªùi gian truy c·∫≠p trung b√¨nh th·ª±c t·∫ø c√≥ kh√°c 3 ph√∫t nh∆∞ k·ª≥ v·ªçng kh√¥ng?
### b. **Independent two-sample t-test (ki·ªÉm ƒë·ªãnh 2 m·∫´u ƒë·ªôc l·∫≠p)**
**M·ª•c ti√™u:** So s√°nh trung b√¨nh c·ªßa **hai nh√≥m kh√¥ng li√™n quan nhau**.
#### üîç C√¥ng th·ª©c:
$$t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} }}$$
**V√≠ d·ª•:** So s√°nh ƒëi·ªÉm ƒë√°nh gi√° trung b√¨nh gi·ªØa 2 nh√≥m ng∆∞·ªùi d√πng A v√† B.
### c. **Paired t-test (2 m·∫´u li√™n quan)**
**M·ª•c ti√™u:** So s√°nh trung b√¨nh **tr∆∞·ªõc v√† sau can thi·ªáp** tr√™n c√πng ƒë·ªëi t∆∞·ª£ng.
#### üîç C√¥ng th·ª©c:
$$t = \frac{\bar{d}}{s_d / \sqrt{n}}‚Äã$$
**V√≠ d·ª•:** So s√°nh hi·ªáu su·∫•t l√†m vi·ªác c·ªßa nh√¢n vi√™n **tr∆∞·ªõc v√† sau ƒë√†o t·∫°o**.
## ‚úÖ **ANOVA (Analysis of Variance)**
**M·ª•c ti√™u:** So s√°nh trung b√¨nh c·ªßa **nhi·ªÅu h∆°n 2 nh√≥m**.
- Gi·∫£ thuy·∫øt H0‚Äã: t·∫•t c·∫£ c√°c nh√≥m c√≥ trung b√¨nh b·∫±ng nhau
- D√πng khi t-test kh√¥ng c√≤n ph√π h·ª£p (v√¨ t ch·ªâ so s√°nh 2 nh√≥m)
#### üîç C√¥ng th·ª©c ki·ªÉm ƒë·ªãnh F:
$$F = \frac{\text{Bi·∫øn thi√™n gi·ªØa c√°c nh√≥m}}{\text{Bi·∫øn thi√™n trong nh√≥m}}$$‚Äã
**V√≠ d·ª•:** So s√°nh ƒëi·ªÉm h√†i l√≤ng trung b√¨nh gi·ªØa 3 chi nh√°nh Highlands Coffee kh√°c nhau.
## ‚úÖ **Chi-square test (ki·ªÉm ƒë·ªãnh Chi b√¨nh ph∆∞∆°ng)**
**M·ª•c ti√™u:** D√πng cho **d·ªØ li·ªáu ph√¢n lo·∫°i**, ƒë·ªÉ ki·ªÉm ƒë·ªãnh:
- M·ªëi li√™n h·ªá gi·ªØa 2 bi·∫øn (ki·ªÉm ƒë·ªãnh ƒë·ªôc l·∫≠p)
- S·ª± ph√¢n ph·ªëi c√≥ kh·ªõp k·ª≥ v·ªçng kh√¥ng (ki·ªÉm ƒë·ªãnh goodness of fit)
#### üîç C√¥ng th·ª©c:
$$\chi^2 = \sum \frac{(O - E)^2}{E}$$‚Äã
- O: gi√° tr·ªã quan s√°t
- E: gi√° tr·ªã k·ª≥ v·ªçng
#### üß† V√≠ d·ª•:
- Ki·ªÉm tra xem gi·ªõi t√≠nh v√† th√≥i quen u·ªëng c√† ph√™ c√≥ li√™n quan kh√¥ng.
- Ki·ªÉm tra xem t·ªâ l·ªá kh√°ch ch·ªçn s·∫£n ph·∫©m c√≥ kh·ªõp d·ª± ƒëo√°n kh√¥ng.
## ‚úÖ **C√°c ki·ªÉm ƒë·ªãnh th·ªëng k√™ kh√°c th∆∞·ªùng d√πng**

| T√™n ki·ªÉm ƒë·ªãnh                           | ·ª®ng d·ª•ng ch√≠nh                                     |
| --------------------------------------- | -------------------------------------------------- |
| **Z-test**                              | So s√°nh trung b√¨nh khi bi·∫øt ƒë·ªô l·ªách chu·∫©n t·ªïng th·ªÉ |
| **Mann-Whitney U test**                 | Thay th·∫ø t-test khi d·ªØ li·ªáu kh√¥ng chu·∫©n            |
| **Wilcoxon signed-rank test**           | Thay th·∫ø paired t-test n·∫øu kh√¥ng chu·∫©n             |
| **Kruskal-Wallis test**                 | Thay ANOVA khi d·ªØ li·ªáu kh√¥ng ph√¢n ph·ªëi chu·∫©n       |
| **Kolmogorov‚ÄìSmirnov test**             | Ki·ªÉm tra ph√¢n ph·ªëi chu·∫©n hay kh√¥ng                 |
| **Shapiro-Wilk / Anderson-Darling**     | Ki·ªÉm ƒë·ªãnh chu·∫©n cho d·ªØ li·ªáu                        |
| **Levene‚Äôs test / Bartlett‚Äôs test**     | Ki·ªÉm tra ph∆∞∆°ng sai ƒë·ªìng nh·∫•t (ti·ªÅn ƒë·ªÅ cho ANOVA)  |
| **Log-rank test**                       | So s√°nh th·ªùi gian s·ªëng gi·ªØa 2 nh√≥m (survival)      |
| **Correlation test (Pearson/Spearman)** | Ki·ªÉm tra m·ªëi t∆∞∆°ng quan                            |
## **T√≥m t·∫Øt ch·ªçn ki·ªÉm ƒë·ªãnh theo lo·∫°i d·ªØ li·ªáu:**

| M·ª•c ti√™u                     | Lo·∫°i d·ªØ li·ªáu       | Ki·ªÉm ƒë·ªãnh ph√π h·ª£p                |
| ---------------------------- | ------------------ | -------------------------------- |
| So s√°nh 1 trung b√¨nh         | Li√™n t·ª•c           | One-sample t-test                |
| So s√°nh 2 nh√≥m ƒë·ªôc l·∫≠p       | Li√™n t·ª•c           | Two-sample t-test / Mann-Whitney |
| So s√°nh 2 nh√≥m li√™n quan     | Li√™n t·ª•c           | Paired t-test / Wilcoxon         |
| So s√°nh >2 nh√≥m              | Li√™n t·ª•c           | ANOVA / Kruskal-Wallis           |
| M·ªëi quan h·ªá 2 bi·∫øn ph√¢n lo·∫°i | Ph√¢n lo·∫°i          | Chi-square test                  |
| M·ªëi t∆∞∆°ng quan               | Li√™n t·ª•c / Th·ª© b·∫≠c | Pearson / Spearman correlation   |
| Ki·ªÉm tra ph√¢n ph·ªëi           | B·∫•t k·ª≥             | Shapiro-Wilk / KS-test           |
# üìå **4. T∆∞∆°ng quan v√† h·ªìi quy**
## **T∆∞∆°ng quan**
T∆∞∆°ng quan l√† **m·ª©c ƒë·ªô li√™n h·ªá tuy·∫øn t√≠nh** gi·ªØa hai bi·∫øn. Tuy nhi√™n, **t∆∞∆°ng quan kh√¥ng h√†m √Ω nh√¢n qu·∫£**.
### **H·ªá s·ªë t∆∞∆°ng quan Pearson r**
D√πng khi c·∫£ hai bi·∫øn l√† li√™n t·ª•c v√† ph√¢n ph·ªëi g·∫ßn chu·∫©n.
$$r = \frac{ \sum (x_i - \bar{x})(y_i - \bar{y}) }{ \sqrt{ \sum (x_i - \bar{x})^2 \cdot \sum (y_i - \bar{y})^2 } }
$$

| Gi√° tr·ªã r | √ù nghƒ©a                           |
| --------- | --------------------------------- |
| r>0       | T∆∞∆°ng quan d∆∞∆°ng (c√πng tƒÉng/gi·∫£m) |
| r<0       | T∆∞∆°ng quan √¢m                     |
| r=0       | Kh√¥ng t∆∞∆°ng quan tuy·∫øn t√≠nh       |
### **H·ªá s·ªë t∆∞∆°ng quan Spearman (rho)**
D√πng khi d·ªØ li·ªáu kh√¥ng chu·∫©n ho·∫∑c l√† **th·ª© b·∫≠c (ordinal)**.
$$œÅ = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}$$


- di‚Äã: hi·ªáu gi·ªØa c√°c h·∫°ng c·ªßa xi‚Äã v√† yi‚Äã
### **Ki·ªÉm ƒë·ªãnh t∆∞∆°ng quan**
- Ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt H0: r=0
- D√πng ƒë·ªÉ ƒë√°nh gi√° m·ªëi li√™n h·ªá c√≥ **√Ω nghƒ©a th·ªëng k√™** hay kh√¥ng (p-value)

## **H·ªìi quy tuy·∫øn t√≠nh (Linear Regression)**
H·ªìi quy l√† k·ªπ thu·∫≠t **d·ª± ƒëo√°n m·ªôt bi·∫øn (bi·∫øn ph·ª• thu·ªôc Y)** d·ª±a tr√™n m·ªôt ho·∫∑c nhi·ªÅu **bi·∫øn gi·∫£i th√≠ch (X)**.
### **H·ªìi quy tuy·∫øn t√≠nh ƒë∆°n (Simple Linear Regression)**
$$Y = \beta_0 + \beta_1 X + \varepsilon
$$
Trong ƒë√≥:

| K√Ω hi·ªáu  | Gi·∫£i th√≠ch             |
| -------- | ---------------------- |
| $$Œ≤_0‚Äã$$ | intercept (h·ªá s·ªë ch·∫∑n) |
| $$Œ≤_1‚Äã$$ | slope (ƒë·ªô d·ªëc)         |
| Œµ        | sai s·ªë                 |

**M·ª•c ti√™u:**
- ∆Ø·ªõc l∆∞·ª£ng m·ªëi quan h·ªá tuy·∫øn t√≠nh gi·ªØa X v√† Y
- D·ª± b√°o gi√° tr·ªã Y khi bi·∫øt X
**ƒê√°nh gi√° m√¥ h√¨nh:**

|                          |                                              |
| ------------------------ | -------------------------------------------- |
| $$R^2$$                  | ph·∫ßn trƒÉm ph∆∞∆°ng sai Y ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi X |
| **p-value** c·ªßa $$Œ≤_1‚Äã$$ | ki·ªÉm ƒë·ªãnh xem X c√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn Y           |

### **H·ªìi quy tuy·∫øn t√≠nh b·ªôi (Multiple Linear Regression)**
D·∫°ng ph∆∞∆°ng tr√¨nh:
$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \varepsilon
$$
> D√πng khi c√≥ nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p
### Ki·ªÉm tra gi·∫£ ƒë·ªãnh c·ªßa h·ªìi quy tuy·∫øn t√≠nh:
1. **Linearity** ‚Äì Quan h·ªá gi·ªØa X v√† Y l√† tuy·∫øn t√≠nh
2. **Independence** ‚Äì D·ªØ li·ªáu ƒë·ªôc l·∫≠p
3. **Homoscedasticity** ‚Äì Ph∆∞∆°ng sai ph·∫ßn d∆∞ ƒë·ªìng ƒë·ªÅu
4. **Normality** ‚Äì Ph·∫ßn d∆∞ ph√¢n ph·ªëi chu·∫©n
### **H·ªìi quy logistic (Logistic Regression)**
D√πng khi bi·∫øn ph·ª• thu·ªôc l√† **nh·ªã ph√¢n (binary: 0/1, yes/no...)**
Ph∆∞∆°ng tr√¨nh:
$$\log \left( \frac{p}{1 - p} \right) = \beta_0 + \beta_1 X
$$
> √Åp d·ª•ng trong ph√¢n lo·∫°i: v√≠ d·ª• d·ª± ƒëo√°n kh√°ch c√≥ r·ªùi b·ªè kh√¥ng (churn)
### **So s√°nh t∆∞∆°ng quan vs h·ªìi quy**

| Ti√™u ch√≠         | T∆∞∆°ng quan         | H·ªìi quy                                     |
| ---------------- | ------------------ | ------------------------------------------- |
| M·ª•c ti√™u         | ƒêo m·ª©c ƒë·ªô li√™n h·ªá  | M√¥ h√¨nh h√≥a v√† d·ª± b√°o                       |
| K·∫øt qu·∫£          | H·ªá s·ªë t∆∞∆°ng quan r | Ph∆∞∆°ng tr√¨nh, h·ªá s·ªë h·ªìi quy Œ≤               |
| Quan h·ªá nh√¢n qu·∫£ | Kh√¥ng              | C√≥ th·ªÉ (n·∫øu c√≥ thi·∫øt k·∫ø nghi√™n c·ª©u ph√π h·ª£p) |

## ‚úÖ ·ª®ng d·ª•ng trong Data Analysis

- T√¨m m·ªëi li√™n h·ªá gi·ªØa h√†nh vi kh√°ch h√†ng v√† doanh thu
- D·ª± ƒëo√°n gi√° tr·ªã b√°n h√†ng theo m√πa
- Ki·ªÉm tra y·∫øu t·ªë n√†o ·∫£nh h∆∞·ªüng m·∫°nh ƒë·∫øn churn rate
- [[1. Data Analyst/3.2 Ph√¢n t√≠ch A B test\|3.2 Ph√¢n t√≠ch A B test]] v√† c√°c y·∫øu t·ªë t√°c ƒë·ªông ƒë·∫øn k·∫øt qu·∫£
# **C√°c kh√°i ni·ªám quan tr·ªçng kh√°c**

|Kh√°i ni·ªám|·ª®ng d·ª•ng|
|---|---|
|Central Limit Theorem|M·∫´u c√†ng l·ªõn ‚Üí ph√¢n ph·ªëi g·∫ßn chu·∫©n h∆°n|
|Law of Large Numbers|S·ªë li·ªáu th·ª±c nghi·ªám g·∫ßn ƒë√∫ng k·ª≥ v·ªçng|
|Overfitting|Tr√°nh trong m√¥ h√¨nh th·ªëng k√™ v√† machine learning|
|Bias vs Variance|C√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô t·ªïng qu√°t|